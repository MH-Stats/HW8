[
  {
    "objectID": "HW8.html",
    "href": "HW8.html",
    "title": "HW8",
    "section": "",
    "text": "The first step will be to read in the data and to do so we will download the data directly from a website and then read it in using functions from the tidyverse.\n\n# Loading librarys\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(purrr)\nlibrary(ggcorrplot)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\n\n\n# Loading in the data\nbike_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\", locale = locale(encoding = \"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Storing orginial names for reference\nattr(bike_data, \"orginal_names\") &lt;- names(bike_data)\n\n# Renaming variables for simplicity\nbike_data &lt;- bike_data |&gt;\n  rename(date = Date, bike_count = `Rented Bike Count`, temp_c = `Temperature(°C)`, humidity = `Humidity(%)`, wind_speed = `Wind speed (m/s)`,\n         visibility = `Visibility (10m)`, dew_point =`Dew point temperature(°C)`, solar_rads = `Solar Radiation (MJ/m2)`, \n         rain = `Rainfall(mm)`, snow = `Snowfall (cm)`, season = Seasons, holiday = Holiday, functioning = `Functioning Day`)\n\n\n\n\nNow the next step is to check if there are any missing values and to make sure that all the columns are listed in a logical manner (aka numeric is numeric). We will also be changing the character variables into factors to make anlyasis easier, and making the date column into the date format.\n\n# Function to check for NA's\nsum_na &lt;- function(col){\nsum(is.na(col))\n}\nbike_data |&gt;\nsummarize(across(everything(), sum_na))\n\n# A tibble: 1 × 14\n   date bike_count  Hour temp_c humidity wind_speed visibility dew_point\n  &lt;int&gt;      &lt;int&gt; &lt;int&gt;  &lt;int&gt;    &lt;int&gt;      &lt;int&gt;      &lt;int&gt;     &lt;int&gt;\n1     0          0     0      0        0          0          0         0\n# ℹ 6 more variables: solar_rads &lt;int&gt;, rain &lt;int&gt;, snow &lt;int&gt;, season &lt;int&gt;,\n#   holiday &lt;int&gt;, functioning &lt;int&gt;\n\n# Converting date column to date format\nbike_data &lt;- bike_data |&gt;\n  mutate(date = dmy(date))\n\n# Getting list of unique rows for character variables in order to make them factors\nseason_uniq &lt;-unique(bike_data$season)\nholiday_uniq &lt;- unique(bike_data$holiday)\nfunctioning_uniq &lt;- unique(bike_data$functioning)\n\n# Creating factors for character vars\nbike_data &lt;- mutate(bike_data, across(c(season, holiday, functioning), as.factor))\n\nNow that we have completed those steps, we need to run some summary statistics in order to get a better idea of how the variables relate to one another. Of special importance is how the variables relate to the bike rental count.\n\n# Creating function to grab numeric summary stats\nnumeric_summary &lt;- function(data){\n  # Selecting numeric vars\n  num_vars &lt;- data |&gt;\n    select(where(is.numeric))\n  # Creating empty list\n  num_sum_list &lt;- list()\n  \n  # Looping summary stats\n  for(num_var in colnames(num_vars)){\n  num_sums &lt;- num_vars |&gt;\n  summarize(across(num_var, .fns = list(\"mean\" = mean, # This will create a named list with .fns\n                                       \"median\" = median,\n                                       \"var\" = var,\n                                       \"sd\" = sd,\n                                       \"IQR\" = IQR), .names = \"{.fn}\")) # .fn is function names\n  num_sums &lt;- num_sums |&gt;\n    mutate(variable = num_var)\n  num_sums &lt;- num_sums |&gt; \n    select(variable, everything())\n  \n  num_sum_list[[num_var]] &lt;- num_sums\n  }\n  return(num_sum_list)\n}\n\n# Running function\nnum_sums &lt;- numeric_summary(bike_data)\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `across(...)`.\nCaused by warning:\n! Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(num_var)\n\n  # Now:\n  data %&gt;% select(all_of(num_var))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\nnum_sums\n\n$bike_count\n# A tibble: 1 × 6\n  variable    mean median     var    sd   IQR\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 bike_count  705.   504. 416022.  645.  874.\n\n$Hour\n# A tibble: 1 × 6\n  variable  mean median   var    sd   IQR\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Hour      11.5   11.5  47.9  6.92  11.5\n\n$temp_c\n# A tibble: 1 × 6\n  variable  mean median   var    sd   IQR\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 temp_c    12.9   13.7  143.  11.9    19\n\n$humidity\n# A tibble: 1 × 6\n  variable  mean median   var    sd   IQR\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 humidity  58.2     57  415.  20.4    32\n\n$wind_speed\n# A tibble: 1 × 6\n  variable    mean median   var    sd   IQR\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 wind_speed  1.72    1.5  1.07  1.04   1.4\n\n$visibility\n# A tibble: 1 × 6\n  variable    mean median     var    sd   IQR\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 visibility 1437.   1698 370027.  608.  1060\n\n$dew_point\n# A tibble: 1 × 6\n  variable   mean median   var    sd   IQR\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 dew_point  4.07    5.1  171.  13.1  19.5\n\n$solar_rads\n# A tibble: 1 × 6\n  variable    mean median   var    sd   IQR\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 solar_rads 0.569   0.01 0.755 0.869  0.93\n\n$rain\n# A tibble: 1 × 6\n  variable  mean median   var    sd   IQR\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 rain     0.149      0  1.27  1.13     0\n\n$snow\n# A tibble: 1 × 6\n  variable   mean median   var    sd   IQR\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 snow     0.0751      0 0.191 0.437     0\n\n# Creating combined summary\nnum_sums_tibble &lt;- bind_rows(num_sums)\n# Setting Scipen so it displays without scientifc notation\noptions(scipen = 999)\n# Printing table\nnum_sums_tibble\n\n# A tibble: 10 × 6\n   variable        mean  median        var      sd     IQR\n   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 bike_count  705.      504.   416022.    645.     874.  \n 2 Hour         11.5      11.5      47.9     6.92    11.5 \n 3 temp_c       12.9      13.7     143.     11.9     19   \n 4 humidity     58.2      57       415.     20.4     32   \n 5 wind_speed    1.72      1.5       1.07    1.04     1.4 \n 6 visibility 1437.     1698    370027.    608.    1060   \n 7 dew_point     4.07      5.1     171.     13.1     19.5 \n 8 solar_rads    0.569     0.01      0.755   0.869    0.93\n 9 rain          0.149     0         1.27    1.13     0   \n10 snow          0.0751    0         0.191   0.437    0   \n\n\nNow that we have created summary stats for our numeric variables we can no go ahead and look at some summary stats for our categorical variables, and to do so we shall create tables of counts for each variable.\n\n# 1 way tables\nseason1way &lt;- table(\"season\" = bike_data$season)\nseason1way\n\nseason\nAutumn Spring Summer Winter \n  2184   2208   2208   2160 \n\nholiday1way &lt;- table(\"holiday\" = bike_data$holiday)\nholiday1way\n\nholiday\n   Holiday No Holiday \n       432       8328 \n\nfunctioning1way &lt;- table(\"functioning\" = bike_data$functioning)\nfunctioning1way\n\nfunctioning\n  No  Yes \n 295 8465 \n\n# 2 way tables\nseason_holiday &lt;- table(bike_data$season, bike_data$holiday)\nseason_holiday\n\n        \n         Holiday No Holiday\n  Autumn     120       2064\n  Spring      72       2136\n  Summer      48       2160\n  Winter     192       1968\n\nseason_functioning &lt;- table(bike_data$season, bike_data$functioning)\nseason_functioning\n\n        \n           No  Yes\n  Autumn  247 1937\n  Spring   48 2160\n  Summer    0 2208\n  Winter    0 2160\n\nholiday_functioning &lt;- table(bike_data$holiday, bike_data$functioning)\nholiday_functioning\n\n            \n               No  Yes\n  Holiday      24  408\n  No Holiday  271 8057\n\n\nNow I want to run summary stats specifically looking at bike rental counts, as I had disccused previously. Specifically, I want to see what factors are correlated with bike rental counts. To start I am going to see if there are any bike rentals when the bikes are not functioning as I assume there will be none.\n\n# Subsetting the data for when bikes do not function\nno_function_data &lt;- bike_data |&gt;\n  group_by(functioning) |&gt;\n  filter(functioning == \"No\")\n\n# Getting the mean for the bike counts for this data\nno_function_data |&gt;\n  mean(bike_count)\n\nWarning in mean.default(no_function_data, bike_count): argument is not numeric\nor logical: returning NA\n\n\n[1] NA\n\n\nWith this we find that there is are no bike rentals when the bikes are not functioning, which confirms my suscipsion. Next we are going to look at correlations between the numeric variables by making a correlation plot.\n\n# subsetting data for plot\nbike_data |&gt;\nselect(-date, -season, - holiday, -functioning) |&gt;\ncor() |&gt;\nggcorrplot(hc.order = TRUE, type = \"full\", lab = TRUE)\n\n\n\n\n\n\n\n\nFrom these results we can see that temperature, dewpoint, and hour have moderate correlations with bike rental count. There are also weak positive correlations between wind speed and solar rads and bike rental counts. Humidity, rain, and snow all have weak negative correlations with bike rental counts.\nNow the next step is going to be to group the date by the date, seasons and holiday variables. After grouping the data we are going to find the sum of bike count, rain fall, and snow fall, then the means of all the weather releated variables.\n\n# Subsetting the data \nbike_sub &lt;- bike_data |&gt;\n  group_by(date, season, holiday) |&gt;\n  summarize(bike_count = sum(bike_count),\n            rain = sum(rain),\n            snow = sum(snow),\n            temp_c = mean(temp_c),\n            humidity = mean(humidity),\n            wind_speed = mean(wind_speed),\n            visibility = mean(visibility),\n            dew_point = mean(dew_point),\n            solar_rads = mean(solar_rads))\n\n`summarise()` has grouped output by 'date', 'season'. You can override using\nthe `.groups` argument.\n\n\nSince our data is in a more useable format for our purposes we will rerun all of the summary statistics we ran before, and also create some plots as well.\n\n# Reworking numeric summary function\nnum_sum_function &lt;- function(data, num_var = \"bike_count\"){\n    data1 &lt;- data |&gt; \n      group_by(date) |&gt;\n    summarize(across(num_var, .fns = list(\"mean\" = mean, # This will create a named list with .fns\n                                       \"median\" = median,\n                                       \"var\" = var,\n                                       \"sd\" = sd,\n                                       \"IQR\" = IQR), .names = \"{.fn}\")) # .fn is function names\n  return(data1)\n}\n\n# Running function through numeric variables\nbike_sub_sum &lt;- num_sum_function(bike_sub)\nrain_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"rain\")\nsnow_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"snow\")\ntemp_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"temp_c\")\nhumidity_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"humidity\")\nwind_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"wind_speed\")\nvisibility_sub_sum &lt;- num_sum_function(bike_sub, \"visibility\")\ndew_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"dew_point\")\nsolar_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"solar_rads\")\n\n# Creating large tibble\nnum_sub_tibble &lt;- bind_rows(bike_sub_sum, rain_sub_sum, snow_sub_sum, temp_sub_sum,\n                            humidity_sub_sum, wind_sub_sum, visibility_sub_sum,\n                            dew_sub_sum, solar_sub_sum)\nnum_sub_tibble\n\n# A tibble: 3,285 × 6\n   date        mean median   var    sd   IQR\n   &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 2017-12-01  9539   9539    NA    NA     0\n 2 2017-12-02  8523   8523    NA    NA     0\n 3 2017-12-03  7222   7222    NA    NA     0\n 4 2017-12-04  8729   8729    NA    NA     0\n 5 2017-12-05  8307   8307    NA    NA     0\n 6 2017-12-06  6669   6669    NA    NA     0\n 7 2017-12-07  8549   8549    NA    NA     0\n 8 2017-12-08  8032   8032    NA    NA     0\n 9 2017-12-09  7233   7233    NA    NA     0\n10 2017-12-10  3453   3453    NA    NA     0\n# ℹ 3,275 more rows\n\n\nAfter running this code I realized that it was not really going to tell me anything, but it was a learning lesson. Instead I am going to now see how my tables turn out with the grouped data.\n\n# 1 way tables\nseason1way2 &lt;- table(\"season\" = bike_sub$season)\nseason1way2\n\nseason\nAutumn Spring Summer Winter \n    91     92     92     90 \n\nholiday1way2 &lt;- table(\"holiday\" = bike_sub$holiday)\nholiday1way2\n\nholiday\n   Holiday No Holiday \n        18        347 \n\n# 2 way tables\nseason_holiday2 &lt;- table(\"season\" = bike_sub$season, \"holiday\" = bike_sub$holiday)\nseason_holiday2\n\n        holiday\nseason   Holiday No Holiday\n  Autumn       5         86\n  Spring       3         89\n  Summer       2         90\n  Winter       8         82\n\n\nNow I have figured out how to get summary statistics by using the summary() function, and will also be figuring out the correlations.\n\n# Creating summary stats\nbike_sub_summary &lt;- summary(bike_sub)\n\n# Creating numerical correlations\ncorr_bike_data &lt;- bike_sub |&gt;\n  ungroup() |&gt;\n  select(where(is.numeric))\n\ncorr_bike_data |&gt;\ncor() |&gt;\nggcorrplot(hc.order = TRUE, type = \"full\", lab = TRUE)\n\n\n\n\n\n\n\n\nCreating scatter plot of bike count by the highest correlated numeric variables to get a better understanding of the how the data is spread. We are going to look at scatterplots of temperature, dew point, solar radation, and snow fall.\n\n# Temperature scatter plot\nggplot(bike_sub, aes(x=temp_c, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Temperature by Bike Rental Count\") +\n  xlab(\"Temperature (C)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n# dew point scatter plot\nggplot(bike_sub, aes(x=dew_point, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Dew Point by Bike Rental Count\") +\n  xlab(\"Dew Point (C)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n# Solar Radation scatter plot\nggplot(bike_sub, aes(x=solar_rads, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Solar Radiation by Bike Rental Count\") +\n  xlab(\"Temperature (MJ/m2)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n# Snow fall scatter plot\nggplot(bike_sub, aes(x=snow, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Snow Fall by Bike Rental Count\") +\n  xlab(\"Snow Fall (cm)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n\nNothing really special can be inferred from the first three plots, as they data follows what you would expect with a fairly linear distribution. The interesting plot is the snow fall one as it shows that when snow fall does occur the amount of bike rentals is drastically reduced, but this happens relatively rarely. To investigate this further we are going to remove instance where snow fall equals zero to get a better idea of how the correlation works by plotting the data\n\n# Subsetting data\nsnow_zero_data &lt;- bike_sub |&gt;\n  filter(snow &gt; 0)\n\n# Correlation when removing zero\ncor(x = snow_zero_data$snow, y = snow_zero_data$bike_count)\n\n[1] -0.07801522\n\n# plot when moving zero\n# Snow fall scatter plot\nggplot(snow_zero_data, aes(x=snow, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Snow Fall by Bike Rental Count\") +\n  xlab(\"Snow Fall (cm)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n\n\n\n\nNow we need to split the data up to make a training and a test set with a 75/25 split. To do so we shall use the strata argument to split the data by seasons, and we will also create a 10 fold CV split on the training data.\n\n# Splitting the data using initial_split\nset.seed(222) \nbike_split &lt;- initial_split(bike_sub, prop = .75)\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\n\n# Creating 10 fold CV split\nbike_cv &lt;- vfold_cv(data = bike_train, v = 10)\n\n\n\n\nNow that the data is how we need it to be we can move on to making some MLR models. For the first recipe we will be ignoring the date variable, and instead use it to create a weekday/weekend factor variable, after that we will standardize the numeric variables, and then create dummy variables for the seasons, holiday, and our new day variable.\n\n# Creating first recipe object\nrecipe1 &lt;- recipe(bike_count ~ ., data = bike_train) |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(weekend_weekday = factor(\n    if_else(date_dow %in% c(\"Sun\", \"Sat\"), \"Weekend\", \"Weekday\"))) |&gt;\n  step_rm(date, date_dow) |&gt;\n  step_normalize(all_numeric()) |&gt;\n  step_dummy(season, holiday, weekend_weekday)\n  \n# Test recipe to make sure it is working properly \ntest_recipe &lt;- prep(recipe1)\ntrans_data &lt;- bake(test_recipe, new_data = NULL)\ntrans_data\n\n# A tibble: 273 × 14\n       rain   snow temp_c humidity wind_speed visibility dew_point solar_rads\n      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1  1.39    -0.207  0.129   0.812      0.178       0.267     0.328     0.853 \n 2 -0.309   -0.207  1.65   -0.202     -0.184       1.14      1.34      1.10  \n 3  0.00134  6.39  -1.25    1.28      -0.893      -1.60     -0.707    -1.57  \n 4 -0.309   -0.207  0.577   0.156     -0.218      -1.87      0.567     1.01  \n 5 -0.309   -0.207  1.05    0.860      0.297       0.427     1.16     -0.301 \n 6 -0.309    0.644 -0.836   0.609     -1.20       -1.25     -0.495    -1.33  \n 7 -0.218   -0.207  0.815   0.564      0.255      -0.605     0.780     0.0113\n 8 -0.309   -0.207  1.58   -0.0892    -0.956       1.09      1.28      1.22  \n 9 -0.0807  -0.207  1.52    0.0121    -0.0932      1.12      1.32     -0.536 \n10  0.375   -0.207  0.407   2.10      -0.692      -0.677     0.902    -1.03  \n# ℹ 263 more rows\n# ℹ 6 more variables: bike_count &lt;dbl&gt;, season_Spring &lt;dbl&gt;,\n#   season_Summer &lt;dbl&gt;, season_Winter &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;,\n#   weekend_weekday_Weekend &lt;dbl&gt;\n\n\nNow that we have made our first recipe we will now need to make our second recipe. In this recipe we will repeat the steps above, but will also add in interaction between seasons and holiday, seasons and temperature, temperature and rainfall.\n\n# Creating second recipe\nrecipe2 &lt;- recipe(bike_count ~ ., data = bike_train) |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(weekend_weekday = factor(\n    if_else(date_dow %in% c(\"Sun\", \"Sat\"), \"Weekend\", \"Weekday\"))) |&gt;\n  step_rm(date, date_dow) |&gt;\n  step_normalize(all_numeric()) |&gt;\n  step_dummy(season, holiday, weekend_weekday) |&gt;\n  step_interact(~ starts_with(\"season\"):holiday_No.Holiday) |&gt;\n  step_interact(~ starts_with(\"season\"):temp_c) |&gt;\n  step_interact(~ temp_c:rain)\n\n# Test recipe to make sure it is working\ntest_recipe2 &lt;- prep(recipe2)\ntrans_data2 &lt;- bake(test_recipe2, new_data = NULL)\ntrans_data2\n\n# A tibble: 273 × 24\n       rain   snow temp_c humidity wind_speed visibility dew_point solar_rads\n      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1  1.39    -0.207  0.129   0.812      0.178       0.267     0.328     0.853 \n 2 -0.309   -0.207  1.65   -0.202     -0.184       1.14      1.34      1.10  \n 3  0.00134  6.39  -1.25    1.28      -0.893      -1.60     -0.707    -1.57  \n 4 -0.309   -0.207  0.577   0.156     -0.218      -1.87      0.567     1.01  \n 5 -0.309   -0.207  1.05    0.860      0.297       0.427     1.16     -0.301 \n 6 -0.309    0.644 -0.836   0.609     -1.20       -1.25     -0.495    -1.33  \n 7 -0.218   -0.207  0.815   0.564      0.255      -0.605     0.780     0.0113\n 8 -0.309   -0.207  1.58   -0.0892    -0.956       1.09      1.28      1.22  \n 9 -0.0807  -0.207  1.52    0.0121    -0.0932      1.12      1.32     -0.536 \n10  0.375   -0.207  0.407   2.10      -0.692      -0.677     0.902    -1.03  \n# ℹ 263 more rows\n# ℹ 16 more variables: bike_count &lt;dbl&gt;, season_Spring &lt;dbl&gt;,\n#   season_Summer &lt;dbl&gt;, season_Winter &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;,\n#   weekend_weekday_Weekend &lt;dbl&gt;, season_Spring_x_holiday_No.Holiday &lt;dbl&gt;,\n#   season_Summer_x_holiday_No.Holiday &lt;dbl&gt;,\n#   season_Winter_x_holiday_No.Holiday &lt;dbl&gt;, season_Spring_x_temp_c &lt;dbl&gt;,\n#   season_Summer_x_temp_c &lt;dbl&gt;, season_Winter_x_temp_c &lt;dbl&gt;, …\n\n\nNow we are needing to repeat the whole process over, but this time we are going to add quadratic terms for each numeric predictor.\n\n# Creating recipe 3\nrecipe3 &lt;- recipe(bike_count ~ ., data = bike_train) |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(weekend_weekday = factor(\n    if_else(date_dow %in% c(\"Sun\", \"Sat\"), \"Weekend\", \"Weekday\"))) |&gt;\n  step_rm(date, date_dow) |&gt;\n  step_normalize(all_numeric()) |&gt;\n  step_dummy(season, holiday, weekend_weekday) |&gt;\n  step_interact(~ starts_with(\"season\"):holiday_No.Holiday) |&gt;\n  step_interact(~ starts_with(\"season\"):temp_c) |&gt;\n  step_interact(~ temp_c:rain) |&gt;\n  step_poly(rain,\n            snow,\n            temp_c,\n            humidity,\n            wind_speed,\n            visibility,\n            dew_point,\n            solar_rads,\n            degree = 2, keep_original_cols = FALSE)\n\n# Test recipe to make sure it is working\ntest_recipe3 &lt;- prep(recipe3)\ntrans_data3 &lt;- bake(test_recipe3, new_data = NULL)\ntrans_data3\n\n# A tibble: 273 × 32\n   bike_count season_Spring season_Summer season_Winter holiday_No.Holiday\n        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n 1     0.351              1             0             0                  1\n 2     0.352              0             1             0                  1\n 3    -1.40               0             0             1                  1\n 4     0.901              1             0             0                  1\n 5     1.14               0             0             0                  1\n 6    -0.939              0             0             1                  0\n 7     0.790              1             0             0                  1\n 8     0.963              0             1             0                  1\n 9    -0.0558             0             1             0                  1\n10    -0.0428             1             0             0                  1\n# ℹ 263 more rows\n# ℹ 27 more variables: weekend_weekday_Weekend &lt;dbl&gt;,\n#   season_Spring_x_holiday_No.Holiday &lt;dbl&gt;,\n#   season_Summer_x_holiday_No.Holiday &lt;dbl&gt;,\n#   season_Winter_x_holiday_No.Holiday &lt;dbl&gt;, season_Spring_x_temp_c &lt;dbl&gt;,\n#   season_Summer_x_temp_c &lt;dbl&gt;, season_Winter_x_temp_c &lt;dbl&gt;,\n#   season_Spring_x_holiday_No.Holiday_x_temp_c &lt;dbl&gt;, …\n\n\nNow that we have created our recipes we need to set up our linear model for usage with the lm engine. This will consist of fitting the models using our 10 CV via the fit_resamples() function and to use that to choose a best model. After selecting our best fit model we will fit the model to the entire training data set using the last_fit() function. This best fit model will then be used to compute the RMSE metric on the test set and to obtain the final model coefficent table on the training set using extract_fit_parsnip() and tidy()\n\n# specifying the model \nbike_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") \n  \n\n# Creating a work flow for the models \nrecipe1flow &lt;- workflow() |&gt;\n  add_recipe(recipe1) |&gt;\n  add_model(bike_model)\n \n\nrecipe2flow &lt;- workflow() |&gt;\n  add_recipe(recipe2) |&gt;\n  add_model(bike_model) \n  \n\nrecipe3flow &lt;- workflow() |&gt;\n  add_recipe(recipe3) |&gt;\n  add_model(bike_model) \n\n# Fitting the models\nrecipe1fit &lt;- recipe1flow |&gt;\n  fit_resamples(bike_cv) \n  \n  \nrecipe2fit &lt;- recipe2flow |&gt;\n  fit_resamples(bike_cv) \n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x10\n\n\n\n\nrecipe3fit &lt;- recipe3flow |&gt;\n  fit_resamples(bike_cv) \n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x10\n\n\n\n\n# binding them together while finding best model\nrbind(recipe1fit |&gt; collect_metrics(),\n      recipe2fit |&gt; collect_metrics(),\n      recipe3fit |&gt; collect_metrics())\n\n# A tibble: 6 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.533    10  0.0483 Preprocessor1_Model1\n2 rsq     standard   0.719    10  0.0549 Preprocessor1_Model1\n3 rmse    standard   0.475    10  0.0546 Preprocessor1_Model1\n4 rsq     standard   0.756    10  0.0648 Preprocessor1_Model1\n5 rmse    standard   0.479    10  0.0537 Preprocessor1_Model1\n6 rsq     standard   0.756    10  0.0644 Preprocessor1_Model1\n\n\nLooking at the table we created we can see that both recipe1 and recipe2 have almost identical RMSEs and RSQs meaning that we should choose the simpler model that being recipe 1. Since we have selected our model we are going to use last_fit() to apply our model to the test data.\n\n# creating new fit object\nbest_fit &lt;- last_fit(bike_model, recipe1, split = bike_split)\n\nfinal_results &lt;- best_fit |&gt;\n  collect_metrics()\nfinal_results\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.699 Preprocessor1_Model1\n2 rsq     standard       0.618 Preprocessor1_Model1\n\n# creating final model\nfinal_model &lt;- extract_fit_parsnip(best_fit)\nfinal_model\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n            (Intercept)                     rain                     snow  \n               -0.17783                 -0.16024                 -0.01886  \n                 temp_c                 humidity               wind_speed  \n               -0.49261                 -0.31527                 -0.09979  \n             visibility                dew_point               solar_rads  \n               -0.02044                  0.98223                  0.39841  \n          season_Spring            season_Summer            season_Winter  \n               -0.36931                 -0.14552                 -0.67749  \n     holiday_No.Holiday  weekend_weekday_Weekend  \n                0.56083                 -0.17951  \n\n\nThe RMSE is .698 and the RSQ is .617 for recipe1, and displayed is the final model."
  },
  {
    "objectID": "HW8.html#bike-sharing-rentals-modeling",
    "href": "HW8.html#bike-sharing-rentals-modeling",
    "title": "HW8",
    "section": "",
    "text": "The first step will be to read in the data and to do so we will download the data directly from a website and then read it in using functions from the tidyverse.\n\n# Loading librarys\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(purrr)\nlibrary(ggcorrplot)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\n\n\n# Loading in the data\nbike_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\", locale = locale(encoding = \"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Storing orginial names for reference\nattr(bike_data, \"orginal_names\") &lt;- names(bike_data)\n\n# Renaming variables for simplicity\nbike_data &lt;- bike_data |&gt;\n  rename(date = Date, bike_count = `Rented Bike Count`, temp_c = `Temperature(°C)`, humidity = `Humidity(%)`, wind_speed = `Wind speed (m/s)`,\n         visibility = `Visibility (10m)`, dew_point =`Dew point temperature(°C)`, solar_rads = `Solar Radiation (MJ/m2)`, \n         rain = `Rainfall(mm)`, snow = `Snowfall (cm)`, season = Seasons, holiday = Holiday, functioning = `Functioning Day`)\n\n\n\n\nNow the next step is to check if there are any missing values and to make sure that all the columns are listed in a logical manner (aka numeric is numeric). We will also be changing the character variables into factors to make anlyasis easier, and making the date column into the date format.\n\n# Function to check for NA's\nsum_na &lt;- function(col){\nsum(is.na(col))\n}\nbike_data |&gt;\nsummarize(across(everything(), sum_na))\n\n# A tibble: 1 × 14\n   date bike_count  Hour temp_c humidity wind_speed visibility dew_point\n  &lt;int&gt;      &lt;int&gt; &lt;int&gt;  &lt;int&gt;    &lt;int&gt;      &lt;int&gt;      &lt;int&gt;     &lt;int&gt;\n1     0          0     0      0        0          0          0         0\n# ℹ 6 more variables: solar_rads &lt;int&gt;, rain &lt;int&gt;, snow &lt;int&gt;, season &lt;int&gt;,\n#   holiday &lt;int&gt;, functioning &lt;int&gt;\n\n# Converting date column to date format\nbike_data &lt;- bike_data |&gt;\n  mutate(date = dmy(date))\n\n# Getting list of unique rows for character variables in order to make them factors\nseason_uniq &lt;-unique(bike_data$season)\nholiday_uniq &lt;- unique(bike_data$holiday)\nfunctioning_uniq &lt;- unique(bike_data$functioning)\n\n# Creating factors for character vars\nbike_data &lt;- mutate(bike_data, across(c(season, holiday, functioning), as.factor))\n\nNow that we have completed those steps, we need to run some summary statistics in order to get a better idea of how the variables relate to one another. Of special importance is how the variables relate to the bike rental count.\n\n# Creating function to grab numeric summary stats\nnumeric_summary &lt;- function(data){\n  # Selecting numeric vars\n  num_vars &lt;- data |&gt;\n    select(where(is.numeric))\n  # Creating empty list\n  num_sum_list &lt;- list()\n  \n  # Looping summary stats\n  for(num_var in colnames(num_vars)){\n  num_sums &lt;- num_vars |&gt;\n  summarize(across(num_var, .fns = list(\"mean\" = mean, # This will create a named list with .fns\n                                       \"median\" = median,\n                                       \"var\" = var,\n                                       \"sd\" = sd,\n                                       \"IQR\" = IQR), .names = \"{.fn}\")) # .fn is function names\n  num_sums &lt;- num_sums |&gt;\n    mutate(variable = num_var)\n  num_sums &lt;- num_sums |&gt; \n    select(variable, everything())\n  \n  num_sum_list[[num_var]] &lt;- num_sums\n  }\n  return(num_sum_list)\n}\n\n# Running function\nnum_sums &lt;- numeric_summary(bike_data)\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `across(...)`.\nCaused by warning:\n! Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(num_var)\n\n  # Now:\n  data %&gt;% select(all_of(num_var))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\nnum_sums\n\n$bike_count\n# A tibble: 1 × 6\n  variable    mean median     var    sd   IQR\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 bike_count  705.   504. 416022.  645.  874.\n\n$Hour\n# A tibble: 1 × 6\n  variable  mean median   var    sd   IQR\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Hour      11.5   11.5  47.9  6.92  11.5\n\n$temp_c\n# A tibble: 1 × 6\n  variable  mean median   var    sd   IQR\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 temp_c    12.9   13.7  143.  11.9    19\n\n$humidity\n# A tibble: 1 × 6\n  variable  mean median   var    sd   IQR\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 humidity  58.2     57  415.  20.4    32\n\n$wind_speed\n# A tibble: 1 × 6\n  variable    mean median   var    sd   IQR\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 wind_speed  1.72    1.5  1.07  1.04   1.4\n\n$visibility\n# A tibble: 1 × 6\n  variable    mean median     var    sd   IQR\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 visibility 1437.   1698 370027.  608.  1060\n\n$dew_point\n# A tibble: 1 × 6\n  variable   mean median   var    sd   IQR\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 dew_point  4.07    5.1  171.  13.1  19.5\n\n$solar_rads\n# A tibble: 1 × 6\n  variable    mean median   var    sd   IQR\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 solar_rads 0.569   0.01 0.755 0.869  0.93\n\n$rain\n# A tibble: 1 × 6\n  variable  mean median   var    sd   IQR\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 rain     0.149      0  1.27  1.13     0\n\n$snow\n# A tibble: 1 × 6\n  variable   mean median   var    sd   IQR\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 snow     0.0751      0 0.191 0.437     0\n\n# Creating combined summary\nnum_sums_tibble &lt;- bind_rows(num_sums)\n# Setting Scipen so it displays without scientifc notation\noptions(scipen = 999)\n# Printing table\nnum_sums_tibble\n\n# A tibble: 10 × 6\n   variable        mean  median        var      sd     IQR\n   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 bike_count  705.      504.   416022.    645.     874.  \n 2 Hour         11.5      11.5      47.9     6.92    11.5 \n 3 temp_c       12.9      13.7     143.     11.9     19   \n 4 humidity     58.2      57       415.     20.4     32   \n 5 wind_speed    1.72      1.5       1.07    1.04     1.4 \n 6 visibility 1437.     1698    370027.    608.    1060   \n 7 dew_point     4.07      5.1     171.     13.1     19.5 \n 8 solar_rads    0.569     0.01      0.755   0.869    0.93\n 9 rain          0.149     0         1.27    1.13     0   \n10 snow          0.0751    0         0.191   0.437    0   \n\n\nNow that we have created summary stats for our numeric variables we can no go ahead and look at some summary stats for our categorical variables, and to do so we shall create tables of counts for each variable.\n\n# 1 way tables\nseason1way &lt;- table(\"season\" = bike_data$season)\nseason1way\n\nseason\nAutumn Spring Summer Winter \n  2184   2208   2208   2160 \n\nholiday1way &lt;- table(\"holiday\" = bike_data$holiday)\nholiday1way\n\nholiday\n   Holiday No Holiday \n       432       8328 \n\nfunctioning1way &lt;- table(\"functioning\" = bike_data$functioning)\nfunctioning1way\n\nfunctioning\n  No  Yes \n 295 8465 \n\n# 2 way tables\nseason_holiday &lt;- table(bike_data$season, bike_data$holiday)\nseason_holiday\n\n        \n         Holiday No Holiday\n  Autumn     120       2064\n  Spring      72       2136\n  Summer      48       2160\n  Winter     192       1968\n\nseason_functioning &lt;- table(bike_data$season, bike_data$functioning)\nseason_functioning\n\n        \n           No  Yes\n  Autumn  247 1937\n  Spring   48 2160\n  Summer    0 2208\n  Winter    0 2160\n\nholiday_functioning &lt;- table(bike_data$holiday, bike_data$functioning)\nholiday_functioning\n\n            \n               No  Yes\n  Holiday      24  408\n  No Holiday  271 8057\n\n\nNow I want to run summary stats specifically looking at bike rental counts, as I had disccused previously. Specifically, I want to see what factors are correlated with bike rental counts. To start I am going to see if there are any bike rentals when the bikes are not functioning as I assume there will be none.\n\n# Subsetting the data for when bikes do not function\nno_function_data &lt;- bike_data |&gt;\n  group_by(functioning) |&gt;\n  filter(functioning == \"No\")\n\n# Getting the mean for the bike counts for this data\nno_function_data |&gt;\n  mean(bike_count)\n\nWarning in mean.default(no_function_data, bike_count): argument is not numeric\nor logical: returning NA\n\n\n[1] NA\n\n\nWith this we find that there is are no bike rentals when the bikes are not functioning, which confirms my suscipsion. Next we are going to look at correlations between the numeric variables by making a correlation plot.\n\n# subsetting data for plot\nbike_data |&gt;\nselect(-date, -season, - holiday, -functioning) |&gt;\ncor() |&gt;\nggcorrplot(hc.order = TRUE, type = \"full\", lab = TRUE)\n\n\n\n\n\n\n\n\nFrom these results we can see that temperature, dewpoint, and hour have moderate correlations with bike rental count. There are also weak positive correlations between wind speed and solar rads and bike rental counts. Humidity, rain, and snow all have weak negative correlations with bike rental counts.\nNow the next step is going to be to group the date by the date, seasons and holiday variables. After grouping the data we are going to find the sum of bike count, rain fall, and snow fall, then the means of all the weather releated variables.\n\n# Subsetting the data \nbike_sub &lt;- bike_data |&gt;\n  group_by(date, season, holiday) |&gt;\n  summarize(bike_count = sum(bike_count),\n            rain = sum(rain),\n            snow = sum(snow),\n            temp_c = mean(temp_c),\n            humidity = mean(humidity),\n            wind_speed = mean(wind_speed),\n            visibility = mean(visibility),\n            dew_point = mean(dew_point),\n            solar_rads = mean(solar_rads))\n\n`summarise()` has grouped output by 'date', 'season'. You can override using\nthe `.groups` argument.\n\n\nSince our data is in a more useable format for our purposes we will rerun all of the summary statistics we ran before, and also create some plots as well.\n\n# Reworking numeric summary function\nnum_sum_function &lt;- function(data, num_var = \"bike_count\"){\n    data1 &lt;- data |&gt; \n      group_by(date) |&gt;\n    summarize(across(num_var, .fns = list(\"mean\" = mean, # This will create a named list with .fns\n                                       \"median\" = median,\n                                       \"var\" = var,\n                                       \"sd\" = sd,\n                                       \"IQR\" = IQR), .names = \"{.fn}\")) # .fn is function names\n  return(data1)\n}\n\n# Running function through numeric variables\nbike_sub_sum &lt;- num_sum_function(bike_sub)\nrain_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"rain\")\nsnow_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"snow\")\ntemp_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"temp_c\")\nhumidity_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"humidity\")\nwind_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"wind_speed\")\nvisibility_sub_sum &lt;- num_sum_function(bike_sub, \"visibility\")\ndew_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"dew_point\")\nsolar_sub_sum &lt;- num_sum_function(bike_sub, num_var = \"solar_rads\")\n\n# Creating large tibble\nnum_sub_tibble &lt;- bind_rows(bike_sub_sum, rain_sub_sum, snow_sub_sum, temp_sub_sum,\n                            humidity_sub_sum, wind_sub_sum, visibility_sub_sum,\n                            dew_sub_sum, solar_sub_sum)\nnum_sub_tibble\n\n# A tibble: 3,285 × 6\n   date        mean median   var    sd   IQR\n   &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 2017-12-01  9539   9539    NA    NA     0\n 2 2017-12-02  8523   8523    NA    NA     0\n 3 2017-12-03  7222   7222    NA    NA     0\n 4 2017-12-04  8729   8729    NA    NA     0\n 5 2017-12-05  8307   8307    NA    NA     0\n 6 2017-12-06  6669   6669    NA    NA     0\n 7 2017-12-07  8549   8549    NA    NA     0\n 8 2017-12-08  8032   8032    NA    NA     0\n 9 2017-12-09  7233   7233    NA    NA     0\n10 2017-12-10  3453   3453    NA    NA     0\n# ℹ 3,275 more rows\n\n\nAfter running this code I realized that it was not really going to tell me anything, but it was a learning lesson. Instead I am going to now see how my tables turn out with the grouped data.\n\n# 1 way tables\nseason1way2 &lt;- table(\"season\" = bike_sub$season)\nseason1way2\n\nseason\nAutumn Spring Summer Winter \n    91     92     92     90 \n\nholiday1way2 &lt;- table(\"holiday\" = bike_sub$holiday)\nholiday1way2\n\nholiday\n   Holiday No Holiday \n        18        347 \n\n# 2 way tables\nseason_holiday2 &lt;- table(\"season\" = bike_sub$season, \"holiday\" = bike_sub$holiday)\nseason_holiday2\n\n        holiday\nseason   Holiday No Holiday\n  Autumn       5         86\n  Spring       3         89\n  Summer       2         90\n  Winter       8         82\n\n\nNow I have figured out how to get summary statistics by using the summary() function, and will also be figuring out the correlations.\n\n# Creating summary stats\nbike_sub_summary &lt;- summary(bike_sub)\n\n# Creating numerical correlations\ncorr_bike_data &lt;- bike_sub |&gt;\n  ungroup() |&gt;\n  select(where(is.numeric))\n\ncorr_bike_data |&gt;\ncor() |&gt;\nggcorrplot(hc.order = TRUE, type = \"full\", lab = TRUE)\n\n\n\n\n\n\n\n\nCreating scatter plot of bike count by the highest correlated numeric variables to get a better understanding of the how the data is spread. We are going to look at scatterplots of temperature, dew point, solar radation, and snow fall.\n\n# Temperature scatter plot\nggplot(bike_sub, aes(x=temp_c, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Temperature by Bike Rental Count\") +\n  xlab(\"Temperature (C)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n# dew point scatter plot\nggplot(bike_sub, aes(x=dew_point, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Dew Point by Bike Rental Count\") +\n  xlab(\"Dew Point (C)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n# Solar Radation scatter plot\nggplot(bike_sub, aes(x=solar_rads, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Solar Radiation by Bike Rental Count\") +\n  xlab(\"Temperature (MJ/m2)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n# Snow fall scatter plot\nggplot(bike_sub, aes(x=snow, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Snow Fall by Bike Rental Count\") +\n  xlab(\"Snow Fall (cm)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n\nNothing really special can be inferred from the first three plots, as they data follows what you would expect with a fairly linear distribution. The interesting plot is the snow fall one as it shows that when snow fall does occur the amount of bike rentals is drastically reduced, but this happens relatively rarely. To investigate this further we are going to remove instance where snow fall equals zero to get a better idea of how the correlation works by plotting the data\n\n# Subsetting data\nsnow_zero_data &lt;- bike_sub |&gt;\n  filter(snow &gt; 0)\n\n# Correlation when removing zero\ncor(x = snow_zero_data$snow, y = snow_zero_data$bike_count)\n\n[1] -0.07801522\n\n# plot when moving zero\n# Snow fall scatter plot\nggplot(snow_zero_data, aes(x=snow, y=bike_count)) +\n  geom_jitter(alpha=0.6) +\n  ggtitle(\"Snow Fall by Bike Rental Count\") +\n  xlab(\"Snow Fall (cm)\") +\n  ylab(\"Bike Count\")\n\n\n\n\n\n\n\n\n\n\n\nNow we need to split the data up to make a training and a test set with a 75/25 split. To do so we shall use the strata argument to split the data by seasons, and we will also create a 10 fold CV split on the training data.\n\n# Splitting the data using initial_split\nset.seed(222) \nbike_split &lt;- initial_split(bike_sub, prop = .75)\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\n\n# Creating 10 fold CV split\nbike_cv &lt;- vfold_cv(data = bike_train, v = 10)\n\n\n\n\nNow that the data is how we need it to be we can move on to making some MLR models. For the first recipe we will be ignoring the date variable, and instead use it to create a weekday/weekend factor variable, after that we will standardize the numeric variables, and then create dummy variables for the seasons, holiday, and our new day variable.\n\n# Creating first recipe object\nrecipe1 &lt;- recipe(bike_count ~ ., data = bike_train) |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(weekend_weekday = factor(\n    if_else(date_dow %in% c(\"Sun\", \"Sat\"), \"Weekend\", \"Weekday\"))) |&gt;\n  step_rm(date, date_dow) |&gt;\n  step_normalize(all_numeric()) |&gt;\n  step_dummy(season, holiday, weekend_weekday)\n  \n# Test recipe to make sure it is working properly \ntest_recipe &lt;- prep(recipe1)\ntrans_data &lt;- bake(test_recipe, new_data = NULL)\ntrans_data\n\n# A tibble: 273 × 14\n       rain   snow temp_c humidity wind_speed visibility dew_point solar_rads\n      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1  1.39    -0.207  0.129   0.812      0.178       0.267     0.328     0.853 \n 2 -0.309   -0.207  1.65   -0.202     -0.184       1.14      1.34      1.10  \n 3  0.00134  6.39  -1.25    1.28      -0.893      -1.60     -0.707    -1.57  \n 4 -0.309   -0.207  0.577   0.156     -0.218      -1.87      0.567     1.01  \n 5 -0.309   -0.207  1.05    0.860      0.297       0.427     1.16     -0.301 \n 6 -0.309    0.644 -0.836   0.609     -1.20       -1.25     -0.495    -1.33  \n 7 -0.218   -0.207  0.815   0.564      0.255      -0.605     0.780     0.0113\n 8 -0.309   -0.207  1.58   -0.0892    -0.956       1.09      1.28      1.22  \n 9 -0.0807  -0.207  1.52    0.0121    -0.0932      1.12      1.32     -0.536 \n10  0.375   -0.207  0.407   2.10      -0.692      -0.677     0.902    -1.03  \n# ℹ 263 more rows\n# ℹ 6 more variables: bike_count &lt;dbl&gt;, season_Spring &lt;dbl&gt;,\n#   season_Summer &lt;dbl&gt;, season_Winter &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;,\n#   weekend_weekday_Weekend &lt;dbl&gt;\n\n\nNow that we have made our first recipe we will now need to make our second recipe. In this recipe we will repeat the steps above, but will also add in interaction between seasons and holiday, seasons and temperature, temperature and rainfall.\n\n# Creating second recipe\nrecipe2 &lt;- recipe(bike_count ~ ., data = bike_train) |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(weekend_weekday = factor(\n    if_else(date_dow %in% c(\"Sun\", \"Sat\"), \"Weekend\", \"Weekday\"))) |&gt;\n  step_rm(date, date_dow) |&gt;\n  step_normalize(all_numeric()) |&gt;\n  step_dummy(season, holiday, weekend_weekday) |&gt;\n  step_interact(~ starts_with(\"season\"):holiday_No.Holiday) |&gt;\n  step_interact(~ starts_with(\"season\"):temp_c) |&gt;\n  step_interact(~ temp_c:rain)\n\n# Test recipe to make sure it is working\ntest_recipe2 &lt;- prep(recipe2)\ntrans_data2 &lt;- bake(test_recipe2, new_data = NULL)\ntrans_data2\n\n# A tibble: 273 × 24\n       rain   snow temp_c humidity wind_speed visibility dew_point solar_rads\n      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1  1.39    -0.207  0.129   0.812      0.178       0.267     0.328     0.853 \n 2 -0.309   -0.207  1.65   -0.202     -0.184       1.14      1.34      1.10  \n 3  0.00134  6.39  -1.25    1.28      -0.893      -1.60     -0.707    -1.57  \n 4 -0.309   -0.207  0.577   0.156     -0.218      -1.87      0.567     1.01  \n 5 -0.309   -0.207  1.05    0.860      0.297       0.427     1.16     -0.301 \n 6 -0.309    0.644 -0.836   0.609     -1.20       -1.25     -0.495    -1.33  \n 7 -0.218   -0.207  0.815   0.564      0.255      -0.605     0.780     0.0113\n 8 -0.309   -0.207  1.58   -0.0892    -0.956       1.09      1.28      1.22  \n 9 -0.0807  -0.207  1.52    0.0121    -0.0932      1.12      1.32     -0.536 \n10  0.375   -0.207  0.407   2.10      -0.692      -0.677     0.902    -1.03  \n# ℹ 263 more rows\n# ℹ 16 more variables: bike_count &lt;dbl&gt;, season_Spring &lt;dbl&gt;,\n#   season_Summer &lt;dbl&gt;, season_Winter &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;,\n#   weekend_weekday_Weekend &lt;dbl&gt;, season_Spring_x_holiday_No.Holiday &lt;dbl&gt;,\n#   season_Summer_x_holiday_No.Holiday &lt;dbl&gt;,\n#   season_Winter_x_holiday_No.Holiday &lt;dbl&gt;, season_Spring_x_temp_c &lt;dbl&gt;,\n#   season_Summer_x_temp_c &lt;dbl&gt;, season_Winter_x_temp_c &lt;dbl&gt;, …\n\n\nNow we are needing to repeat the whole process over, but this time we are going to add quadratic terms for each numeric predictor.\n\n# Creating recipe 3\nrecipe3 &lt;- recipe(bike_count ~ ., data = bike_train) |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(weekend_weekday = factor(\n    if_else(date_dow %in% c(\"Sun\", \"Sat\"), \"Weekend\", \"Weekday\"))) |&gt;\n  step_rm(date, date_dow) |&gt;\n  step_normalize(all_numeric()) |&gt;\n  step_dummy(season, holiday, weekend_weekday) |&gt;\n  step_interact(~ starts_with(\"season\"):holiday_No.Holiday) |&gt;\n  step_interact(~ starts_with(\"season\"):temp_c) |&gt;\n  step_interact(~ temp_c:rain) |&gt;\n  step_poly(rain,\n            snow,\n            temp_c,\n            humidity,\n            wind_speed,\n            visibility,\n            dew_point,\n            solar_rads,\n            degree = 2, keep_original_cols = FALSE)\n\n# Test recipe to make sure it is working\ntest_recipe3 &lt;- prep(recipe3)\ntrans_data3 &lt;- bake(test_recipe3, new_data = NULL)\ntrans_data3\n\n# A tibble: 273 × 32\n   bike_count season_Spring season_Summer season_Winter holiday_No.Holiday\n        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n 1     0.351              1             0             0                  1\n 2     0.352              0             1             0                  1\n 3    -1.40               0             0             1                  1\n 4     0.901              1             0             0                  1\n 5     1.14               0             0             0                  1\n 6    -0.939              0             0             1                  0\n 7     0.790              1             0             0                  1\n 8     0.963              0             1             0                  1\n 9    -0.0558             0             1             0                  1\n10    -0.0428             1             0             0                  1\n# ℹ 263 more rows\n# ℹ 27 more variables: weekend_weekday_Weekend &lt;dbl&gt;,\n#   season_Spring_x_holiday_No.Holiday &lt;dbl&gt;,\n#   season_Summer_x_holiday_No.Holiday &lt;dbl&gt;,\n#   season_Winter_x_holiday_No.Holiday &lt;dbl&gt;, season_Spring_x_temp_c &lt;dbl&gt;,\n#   season_Summer_x_temp_c &lt;dbl&gt;, season_Winter_x_temp_c &lt;dbl&gt;,\n#   season_Spring_x_holiday_No.Holiday_x_temp_c &lt;dbl&gt;, …\n\n\nNow that we have created our recipes we need to set up our linear model for usage with the lm engine. This will consist of fitting the models using our 10 CV via the fit_resamples() function and to use that to choose a best model. After selecting our best fit model we will fit the model to the entire training data set using the last_fit() function. This best fit model will then be used to compute the RMSE metric on the test set and to obtain the final model coefficent table on the training set using extract_fit_parsnip() and tidy()\n\n# specifying the model \nbike_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") \n  \n\n# Creating a work flow for the models \nrecipe1flow &lt;- workflow() |&gt;\n  add_recipe(recipe1) |&gt;\n  add_model(bike_model)\n \n\nrecipe2flow &lt;- workflow() |&gt;\n  add_recipe(recipe2) |&gt;\n  add_model(bike_model) \n  \n\nrecipe3flow &lt;- workflow() |&gt;\n  add_recipe(recipe3) |&gt;\n  add_model(bike_model) \n\n# Fitting the models\nrecipe1fit &lt;- recipe1flow |&gt;\n  fit_resamples(bike_cv) \n  \n  \nrecipe2fit &lt;- recipe2flow |&gt;\n  fit_resamples(bike_cv) \n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x10\n\n\n\n\nrecipe3fit &lt;- recipe3flow |&gt;\n  fit_resamples(bike_cv) \n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x10\n\n\n\n\n# binding them together while finding best model\nrbind(recipe1fit |&gt; collect_metrics(),\n      recipe2fit |&gt; collect_metrics(),\n      recipe3fit |&gt; collect_metrics())\n\n# A tibble: 6 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.533    10  0.0483 Preprocessor1_Model1\n2 rsq     standard   0.719    10  0.0549 Preprocessor1_Model1\n3 rmse    standard   0.475    10  0.0546 Preprocessor1_Model1\n4 rsq     standard   0.756    10  0.0648 Preprocessor1_Model1\n5 rmse    standard   0.479    10  0.0537 Preprocessor1_Model1\n6 rsq     standard   0.756    10  0.0644 Preprocessor1_Model1\n\n\nLooking at the table we created we can see that both recipe1 and recipe2 have almost identical RMSEs and RSQs meaning that we should choose the simpler model that being recipe 1. Since we have selected our model we are going to use last_fit() to apply our model to the test data.\n\n# creating new fit object\nbest_fit &lt;- last_fit(bike_model, recipe1, split = bike_split)\n\nfinal_results &lt;- best_fit |&gt;\n  collect_metrics()\nfinal_results\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.699 Preprocessor1_Model1\n2 rsq     standard       0.618 Preprocessor1_Model1\n\n# creating final model\nfinal_model &lt;- extract_fit_parsnip(best_fit)\nfinal_model\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n            (Intercept)                     rain                     snow  \n               -0.17783                 -0.16024                 -0.01886  \n                 temp_c                 humidity               wind_speed  \n               -0.49261                 -0.31527                 -0.09979  \n             visibility                dew_point               solar_rads  \n               -0.02044                  0.98223                  0.39841  \n          season_Spring            season_Summer            season_Winter  \n               -0.36931                 -0.14552                 -0.67749  \n     holiday_No.Holiday  weekend_weekday_Weekend  \n                0.56083                 -0.17951  \n\n\nThe RMSE is .698 and the RSQ is .617 for recipe1, and displayed is the final model."
  }
]